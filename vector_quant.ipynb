{
 "metadata": {
  "name": "vector_quant"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%load_ext autoreload\n",
      "#%autoreload 2\n",
      "\n",
      "from scipy.cluster import vq\n",
      "import numpy as np\n",
      "import json\n",
      "from collections import defaultdict, namedtuple\n",
      "from operator import itemgetter\n",
      "import cStringIO\n",
      "\n",
      "import data_wrangling_page as dw\n",
      "\n",
      "from data_wrangling_page import getBody\n",
      "from data_wrangling_page import httpGoogle\n",
      "from data_wrangling_page import getSchemaFields\n",
      "\n",
      "from data_wrangling_page import loadTableFromCSV\n",
      "from data_wrangling_page import queryTableData\n",
      "from data_wrangling_page import queryGoogle\n",
      "\n",
      "from datetime import datetime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Initial Results (9 files)\n",
      "cutting:\n",
      "2012-09-04 07:59:33.246089 -starttime\n",
      "1.41955496309 lowest distortion\n",
      "2012-09-04 08:07:55.862776 -endtime\n",
      "0:08:22.616687 duration.\n",
      "\n",
      "suturing:\n",
      "2012-09-04 08:20:37.537422\n",
      "1.0831198433\n",
      "2012-09-04 08:27:00.092817\n",
      "0:06:22.555395\n",
      "\n",
      "\n",
      "pegtransfer:\n",
      "\n",
      "2012-09-04 08:48:08.336336\n",
      "1.81233551748\n",
      "2012-09-04 08:55:38.810838\n",
      "0:07:30.474502"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Results (558 files)\n",
      "Cluster: 19 machines 1 master\n",
      "Peg Transfer: task\n",
      "2012-09-05 04:52:47.095077 start time\n",
      "1.62632084185 lowest distortion\n",
      "2012-09-05 04:56:50.470700 endtime\n",
      "0:04:03.375623 duration\n",
      "\n",
      "Cutting:\n",
      "2012-09-05 05:23:56.818599\n",
      "1.5186917313\n",
      "2012-09-05 05:28:40.822344\n",
      "0:04:44.003745\n",
      "\n",
      "Suturing:\n",
      "2012-09-05 05:31:51.683836\n",
      "1.42123512532\n",
      "2012-09-05 05:35:45.736178\n",
      "0:03:54.052342"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "550+ samples features = QgFg (L/R)\n",
      "\n",
      "suturing: \n",
      "2012-09-06 11:33:43.069555\n",
      "distortion_left 0.0782727991679\n",
      "distortion_right 0.0777836563702\n",
      "2012-09-06 12:06:13.599771\n",
      "0:32:30.530216  \n",
      "\n",
      "cutting:  \n",
      "2012-09-06 11:00:54.851233\n",
      "distortion_left 0.0679669846974\n",
      "distortion_right 0.0666527180284\n",
      "2012-09-06 11:31:46.766268\n",
      "0:30:51.915035\n",
      "\n",
      "peg transfer:\n",
      "2012-09-06 10:33:05.906191\n",
      "distortion_left 0.0995422580172\n",
      "distortion_right 0.0994004187369\n",
      "2012-09-06 10:58:57.604016\n",
      "0:25:51.697825"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Suturing Qg and Fg:\n",
      "2012-09-10 20:20:03.047888\n",
      "distortion_left 0.0426903171195\n",
      "distortion_right 0.0405832744826\n",
      "2012-09-10 20:40:35.902251\n",
      "0:20:32.854363\n",
      "\n",
      "Cutting:\n",
      "2012-09-11 20:35:59.647566\n",
      "distortion_left 0.0419672938211\n",
      "distortion_right 0.0403074226113\n",
      "2012-09-11 20:56:47.522063\n",
      "0:20:47.874497"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "1000 kmeans runs X 1 run per time\n",
      "using matlab quantiles & python normalization\n",
      "This is not getting lower.\n",
      "2012-09-12 04:08:33.913603\n",
      "distortion_left 0.0401090267562\n",
      "distortion_right 0.0412857620919\n",
      "2012-09-12 07:12:44.583323\n",
      "3:04:10.669720"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Create Codebook"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'starting client'\n",
      "from IPython.parallel import Client\n",
      "ipclient = Client('/home/ubuntu/.starcluster/ipcluster/simcluster-us-east-1.json'\n",
      "            ,sshkey='/home/ubuntu/.ssh/simcluster.rsa'\n",
      "            ,packer='pickle')\n",
      "ipview = ipclient[:]\n",
      "\n",
      "print 'getting features'\n",
      "task = 'suturing'\n",
      "size = size_codebook(task)\n",
      "sensors = ['QgL', 'FgL','QgR', 'FgR'] \n",
      "\n",
      "features, thresholds = getFeatures('timdata', task, sensors)\n",
      "\n",
      "#Normalize\n",
      "normFeatures = normalizeTim(features, thresholds, sensors)\n",
      "leftFeat = normFeatures[:,:2]\n",
      "rightFeat = normFeatures[:,2:]\n",
      "\n",
      "def create_codebook(args):\n",
      "    features, size, i = args\n",
      "    \n",
      "    import scipy.cluster as c\n",
      "    left = c.vq.kmeans((features[0], size)\n",
      "    right = c.vq.kmeans(features[1], size)\n",
      "    return (left, right)\n",
      "\n",
      "print 'starting timing'\n",
      "start = datetime.now()\n",
      "print start\n",
      "\n",
      "run_view = ipview.map_async(create_codebook, [((leftFeat, rightFeat), size, i, 1) for i in range(100)])\n",
      "results = run_view.get()\n",
      "#resultsR = ipview.map_async(create_codebook, [(featuresR, size, i) for i in range(100)])\n",
      "lowest_distortion_left = min(results[0], key=itemgetter(1))\n",
      "lowest_distortion_right = min(results[1], key=itemgetter(1))\n",
      "json.dump(lowest_distortion_left[0].tolist(),  open('left_tim_codebook_{0}_QgFg_thresh'.format(task), 'w'))\n",
      "json.dump(lowest_distortion_right[0].tolist(),  open('right_tim_codebook_{0}_QgFg_thresh'.format(task), 'w'))\n",
      "\n",
      "print 'distortion_left', lowest_distortion_left[1]\n",
      "print 'distortion_right', lowest_distortion_right[1]\n",
      "end = datetime.now()\n",
      "print end\n",
      "print end - start\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print leftFeat[:10,:]\n",
      "#print '\\n', features[:10,:2]\n",
      "\n",
      "#import matplotlib.pyplot as plt\n",
      "#plt.hist(leftFeat,50)\n",
      "#print results\n",
      "#print normFeatures\n",
      "#np.savetxt(\"normFeatures.csv\", normFeatures, delimiter=\",\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Normalize all features by mapping 2nd and 98th percentiles to -1 and 1 \n",
      "#(features must have outliers removed)\n",
      "def normalize(features,thresholds,sensors):\n",
      "    (rows,cols) = features.shape\n",
      "    normFeatures = np.zeros((rows,cols))\n",
      "\n",
      "    #print rows, cols\n",
      "    for col in range(cols):\n",
      "        feature = features[:,col]\n",
      "        print 'normalizing', sensors[col]+'...'\n",
      "    \n",
      "        #Retrieve 2nd and 98th thresholds\n",
      "        lowNormT =  float(thresholds[sensors[col]]['lowNorm'])\n",
      "        highNormT = float(thresholds[sensors[col]]['highNorm'])\n",
      "    \n",
      "        #Perform normalization as based on Tim Code (i.e. Map 2nd and 98th perc. to [-1 1]\n",
      "        normFeatures[:,col] = (feature - lowNormT)* (2/(highNormT-lowNormT)) - 1\n",
      "    \n",
      "    #normFeatures now normalized version of features\n",
      "    print 'Done'   \n",
      "\n",
      "    return normFeatures\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "quantiles = namedtuple('quantiles', 'lowOutlier lowNorm highNorm highOutlier')\n",
      "permil = quantiles(4, 19, 979, 994)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def size_codebook(task):\n",
      "    if task in ['cutting']: return 67\n",
      "    if task in ['suturing']: return 70\n",
      "    if task in ['pegtransfer']: return 57\n",
      "    return 70"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def codebookApply(features, codebook):\n",
      "    '''\n",
      "    returns the code and distance for the codebook\n",
      "    '''\n",
      "    return vq.vq(features, codebook)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def floats(s):\n",
      "    try:\n",
      "        return float(s)\n",
      "    except Exception as e:\n",
      "        return s\n",
      "        #print 'error :', e\n",
      "        #return np.NaN"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getSensors(table_name):\n",
      "    fields = json.loads(getSchemaFields(table_name))\n",
      "    sensors =  [field['name'] for field in fields][4:]\n",
      "    return sensors\n",
      "\n",
      "#print getSensors('timdata')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getTasks(table_name):\n",
      "    tasks = queryGoogle(\"SELECT task from data.{0} GROUP BY task\".format(table_name))\n",
      "    return [task['f'][0]['v'] for task in tasks['rows']]\n",
      "\n",
      "#print getTasks('timdata')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " Gr -- includes grasp angle Qg and grasp force Fg (This requires no estimated derivatives or tip position, but provides very little SIG)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2. SpdAcc-dRta -- Scalar speed, acceleration, and rate of rotation (shown to generate the most SIG)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getFeatures(table_name, task, dataset=None, sensors=None):\n",
      "    sensors = sensors if sensors else getSensors(table_name)\n",
      "    dataset = dataset if dataset else table_name\n",
      "    thresholds = {task: getThresholds(table_name, dataset, task)}\n",
      "    outliers = qOutliers(task, table_name, thresholds, sensors)\n",
      "    results = queryGoogle(outliers)\n",
      "\n",
      "    return (np.array([[floats(field['v']) for field in row['f']]for row in results['rows']]), thresholds[task])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getThresholds(table_name, dataset=None, task_type=None):\n",
      "    dataset = dataset if dataset else table_name\n",
      "    thresholds = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
      "    #data = queryTableData('data', 'thresholds')\n",
      "    qs = \"SELECT task, table_name, threshold, sensor_name, sensor_value FROM data.thresholds WHERE table_name='{0}'\".format(dataset)\n",
      "    data = queryGoogle(qs)\n",
      "    for row in data['rows']:\n",
      "        cells = row['f']\n",
      "        task = 'pegtransfer' if cells[0]['v']=='PegTx' else cells[0]['v'].lower()\n",
      "        ttype = cells[2]['v']\n",
      "        sensor = cells[3]['v']\n",
      "        thresholds[task][sensor][ttype] = cells[4]['v']\n",
      "    \n",
      "    if task_type:\n",
      "        return thresholds.get(task_type, 'ERROR: task not found')\n",
      "    \n",
      "    return thresholds\n",
      "\n",
      "\n",
      "#print getThresholds('timdata')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def createThresholds(table_name):\n",
      "    sensors = getSensors(table_name)\n",
      "    thresholds = cStringIO.StringIO()\n",
      "    for task in getTasks(table_name):\n",
      "        quantiles = {sensor: queryGoogle(qQuantiles(sensor, table_name, task)) for sensor in sensors}\n",
      "        for field in permil._fields:\n",
      "            p = getattr(permil, field)\n",
      "            for sensor in sensors:\n",
      "                thresholds.write('{0},{1},{2},{3},{4}\\n'.format(task, table_name, field, sensor, quantiles[sensor]['rows'][p]['f'][0]['v']))\n",
      "        #thresholds = cStringIO.StringIO(open('thresholds.csv').read()) #to hardcode thresholds from matlab\n",
      "    return thresholds\n",
      "\n",
      "#print createThresholds('timdataMatlab').getvalue()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def createThresholdsTable(table_name):\n",
      "    data = createThresholds(table_name)\n",
      "    fields = getSchemaFields('thresholds')       \n",
      "    body = getBody(data.getvalue(), fields, 'thresholds', 'data'\n",
      "                               , createDisposition='CREATE_IF_NEEDED'\n",
      "                               , writeDisposition='WRITE_APPEND')\n",
      "    loadTableFromCSV(body)\n",
      "#createThresholdsTable('timdata')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Utilities"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##query to get Quantiles"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    \n",
      "def qQuantiles(sensor, table_name, task): \n",
      "    return \"SELECT QUANTILES({0}, 1000) as q{0} FROM [data.{1}] WHERE task=='{2}'\".format(sensor, table_name, task)\n",
      "\n",
      "left = ['QgL', 'FgL']\n",
      "right = ['QgR', 'FgR'] \n",
      "sensors = ['QgL', 'FgL', 'QgR', 'FgR']\n",
      "d =  {sensor: queryGoogle(qQuantiles(sensor, 'timdata', 'suturing')) for sensor in sensors}\n",
      "print d\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def qThresholdSchema(task, table_name):\n",
      "    sensors = getSensors(table_name)\n",
      "    fields = ', '.join(sensors)\n",
      "    return \"SELECT threshold, task, {0} FROM data.schemata WHERE task=='{1}' AND table_name=='{2}'\".format(fields, task, table_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##query to remove outliers based on thresholds"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def qOutliers(task, table_name, thresholds, sensors=None):\n",
      "    sensors = sensors if sensors else getSensors(table_name) \n",
      "    SELECT = (\"SELECT key, \")   \n",
      "    select = [] \n",
      "    FROM = (\" FROM [data.\"+ table_name +\"] \")\n",
      "    WHERE = (\"WHERE task='{0}' AND \".format(task))\n",
      "    where = []\n",
      "    for sensor in sensors:\n",
      "        select.append(sensor)\n",
      "        if abs(float(thresholds[task][sensor]['lowNorm']) - float(thresholds[task][sensor]['highNorm'])) > 0.01 or \\\n",
      "           abs(float(thresholds[task][sensor]['lowOutlier']) - float(thresholds[task][sensor]['highOutlier'])) > 0.01:\n",
      "            where.append(\"({0} > {1} AND {0} < {2})\\n\".format(sensor, \n",
      "                                                             thresholds[task][sensor]['lowOutlier'], \n",
      "                                                             thresholds[task][sensor]['highOutlier']))\n",
      "    \n",
      "    return SELECT + (', '.join(select)) + FROM + WHERE + ' AND '.join(where) \n",
      "\n",
      "\n",
      "#sensors = ['QgL', 'FgL', 'QgR', 'FgR']\n",
      "#print qOutliers('suturing', 'timdata', getThresholds('timdata', 'timdataMatlab'), sensors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f='''sensors = ['QgL', 'FgL', 'QgR', 'FgR']\n",
      "#print thresholds[sensors[0]]['lowNorm'], thresholds[sensors[0]]['highNorm']\n",
      "print thresholds[sensors[0]]['lowOutlier'], thresholds[sensors[0]]['lowNorm'], thresholds[sensors[0]]['highNorm'], thresholds[sensors[0]]['highOutlier']\n",
      "\n",
      "#print thresholds[sensors[1]]['lowNorm'], thresholds[sensors[1]]['highNorm']\n",
      "#print thresholds[sensors[1]]['lowOutlier'], thresholds[sensors[1]]['highOutlier']'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}